%filename: design_add_search_words_data_structure

\problemsection{Design Add and Search Words Data Structure}
\label{problem:design_add_search_words_data_structure}
\marginnote{This problem leverages a trie (prefix tree) to efficiently add and search words, including those with wildcard characters.}

The \textbf{Design Add and Search Words Data Structure} problem involves creating a data structure that allows for the addition of words and the searching of words, where the search functionality supports wildcard characters represented by `.`. Each `.` can match any single letter, enabling flexible search patterns.

\section*{Problem Statement}

Design a class \texttt{WordDictionary} that supports the following two operations:

\begin{itemize}
    \item \texttt{addWord(word)}: Adds a word into the data structure.
    \item \texttt{search(word)}: Returns \texttt{True} if there is any string in the data structure that matches the given word or \texttt{False} otherwise. A word could contain the dot character `.` to represent any one letter.
\end{itemize}

\textbf{Note:}
\begin{itemize}
    \item You may assume that all words consist of lowercase letters `a` to `z`.
    \item The number of operations (\texttt{addWord} and \texttt{search}) will not exceed \(10^5\).
\end{itemize}

\textbf{Examples:}

\textit{Example 1:}

\begin{verbatim}
Input:
["WordDictionary","addWord","addWord","addWord","search","search","search","search"]
[[],["bad"],["dad"],["mad"],["pad"],["bad"],[".ad"],["b.."]]

Output:
[null,null,null,null,false,true,true,true]

Explanation:
WordDictionary wordDictionary = new WordDictionary();
wordDictionary.addWord("bad");
wordDictionary.addWord("dad");
wordDictionary.addWord("mad");
wordDictionary.search("pad"); // return False
wordDictionary.search("bad"); // return True
wordDictionary.search(".ad"); // return True
wordDictionary.search("b.."); // return True
\end{verbatim}

LeetCode link: \href{https://leetcode.com/problems/design-add-and-search-words-data-structure/}{Design Add and Search Words Data Structure}\index{LeetCode}

\marginnote{\href{https://leetcode.com/problems/design-add-and-search-words-data-structure/}{[LeetCode Link]}\index{LeetCode}}
\marginnote{\href{https://www.geeksforgeeks.org/design-add-search-words-data-structure/}{[GeeksForGeeks Link]}\index{GeeksForGeeks}}
\marginnote{\href{https://www.interviewbit.com/problems/design-add-search-words-data-structure/}{[InterviewBit Link]}\index{InterviewBit}}
\marginnote{\href{https://app.codesignal.com/challenges/design-add-search-words-data-structure}{[CodeSignal Link]}\index{CodeSignal}}
\marginnote{\href{https://www.codewars.com/kata/design-add-search-words-data-structure/train/python}{[Codewars Link]}\index{Codewars}}

\section*{Algorithmic Approach}

To efficiently support the operations required by the problem, a \textbf{trie (prefix tree)} data structure is a suitable choice. A trie is a tree-like structure where each node represents a character of a string, allowing for efficient storage and retrieval of words, especially when dealing with prefixes.

\begin{enumerate}
    \item \textbf{Adding a Word (\texttt{addWord(word)}):}  
    Insert the word into the trie by traversing or creating nodes for each character. Mark the end of the word with a special flag.
    
    \item \textbf{Searching a Word (\texttt{search(word)}):}  
    Implement a recursive search that handles both exact characters and wildcards (`.`). When encountering a `.`, recursively search all possible child nodes at that position.
\end{enumerate}

\marginnote{Utilizing a trie allows for efficient addition and flexible search operations, handling wildcards with backtracking techniques.}

\section*{Complexities}

\begin{itemize}
    \item \textbf{Time Complexity:}
    \begin{itemize}
        \item \texttt{addWord}: \(O(m)\), where \(m\) is the length of the word being added, as each character is processed once.
        \item \texttt{search}: \(O(n \cdot 26^m)\) in the worst case, where \(n\) is the number of words and \(m\) is the length of the search word. The presence of wildcards can lead to exploring multiple branches.
    \end{itemize}
    \item \textbf{Space Complexity:} \(O(t)\), where \(t\) is the total number of nodes in the trie. In the worst case, when all words have no common prefixes, this can be \(O(n \cdot m)\), with \(n\) being the number of words and \(m\) the average length.
\end{itemize}

\section*{Python Implementation}

\marginnote{Implementing a trie involves creating nodes for each character and handling the end-of-word flag. Recursive search enables wildcard functionality.}

Below is the complete Python code that implements the \texttt{WordDictionary} class to solve the problem:

\begin{fullwidth}
\begin{lstlisting}[language=Python]
class TrieNode:
    def __init__(self):
        self.children = {}
        self.is_end_of_word = False

class WordDictionary:

    def __init__(self):
        self.root = TrieNode()

    def addWord(self, word: str) -> None:
        node = self.root
        for char in word:
            if char not in node.children:
                node.children[char] = TrieNode()
            node = node.children[char]
        node.is_end_of_word = True

    def search(self, word: str) -> bool:
        def search_in_node(word, node):
            for i, char in enumerate(word):
                if char == '.':
                    for child in node.children.values():
                        if search_in_node(word[i + 1:], child):
                            return True
                    return False
                else:
                    if char not in node.children:
                        return False
                    node = node.children[char]
            return node.is_end_of_word

        return search_in_node(word, self.root)

# Example usage:
wordDictionary = WordDictionary()
wordDictionary.addWord("bad")
wordDictionary.addWord("dad")
wordDictionary.addWord("mad")
print(wordDictionary.search("pad"))  # Output: False
print(wordDictionary.search("bad"))  # Output: True
print(wordDictionary.search(".ad"))  # Output: True
print(wordDictionary.search("b.."))  # Output: True
\end{lstlisting}
\end{fullwidth}

\section*{Explanation}

The \texttt{WordDictionary} class is designed to efficiently handle the addition and searching of words, including those with wildcard characters. Here's a detailed breakdown of the implementation:

\subsection*{Data Structures}
\begin{itemize}
    \item \texttt{TrieNode}:  
    Each node in the trie contains:
    \begin{itemize}
        \item \texttt{children}: A dictionary mapping characters to their corresponding child nodes.
        \item \texttt{is\_end\_of\_word}: A boolean flag indicating whether the node represents the end of a word.
    \end{itemize}
    
    \item \texttt{WordDictionary}:  
    Contains the root of the trie and methods to add and search words.
\end{itemize}

\subsection*{Adding a Word (\texttt{addWord})}
\begin{enumerate}
    \item Start at the root node.
    \item Iterate through each character in the word:
    \begin{itemize}
        \item If the character does not exist in the current node's children, create a new \texttt{TrieNode} for it.
        \item Move to the child node corresponding to the character.
    \end{itemize}
    \item After processing all characters, mark the final node's \texttt{is\_end\_of\_word} as \texttt{True} to indicate the completion of a word.
\end{enumerate}

\subsection*{Searching a Word (\texttt{search})}
\begin{enumerate}
    \item Implement a helper function \texttt{search\_in\_node} that takes the remaining word and the current trie node.
    \item Iterate through each character in the word:
    \begin{itemize}
        \item If the character is not a `.`, check if it exists in the current node's children:
        \begin{itemize}
            \item If it does, move to the corresponding child node.
            \item If it does not, return \texttt{False}.
        \end{itemize}
        \item If the character is a `.`, iterate through all possible child nodes:
        \begin{itemize}
            \item Recursively call \texttt{search\_in\_node} for the remaining substring and each child node.
            \item If any recursive call returns \texttt{True}, return \texttt{True}.
        \end{itemize}
    \end{itemize}
    \item After processing all characters, return the value of \texttt{is\_end\_of\_word} to determine if a complete word matches.
\end{enumerate}

This recursive approach effectively handles wildcard characters by exploring all potential paths in the trie that could match the search pattern.

\section*{Why This Approach}

Using a trie data structure offers several advantages for this problem:

\begin{itemize}
    \item \textbf{Efficiency in Prefix Handling:}  
    Tries are optimized for operations involving prefixes, making them ideal for word storage and retrieval.
    
    \item \textbf{Flexible Search Capability:}  
    The recursive search method allows for efficient handling of wildcard characters by exploring multiple branches only when necessary.
    
    \item \textbf{Space Optimization:}  
    By sharing common prefixes among words, tries can be more space-efficient compared to storing each word independently, especially when many words share similar prefixes.
    
    \item \textbf{Scalability:}  
    The trie structure can handle a large number of words and operations within the problem constraints (\(10^5\) operations), maintaining performance even as the dataset grows.
\end{itemize}

This method is optimal for the problem constraints, ensuring both speed and accuracy in word addition and search operations.

\section*{Alternative Approaches}

While a trie is the most efficient structure for this problem, alternative methods include:

\begin{itemize}
    \item \textbf{Hash Table with Regex Matching:}  
    Store all words in a hash table and perform regex-based searches to handle wildcards. However, this approach is less efficient, especially for large datasets, as regex matching can be time-consuming.
    
    \item \textbf{Backtracking with Lists:}  
    Maintain a list of all added words and perform backtracking searches for wildcard patterns. This method lacks the efficiency of a trie, leading to slower search times, particularly with many words or multiple wildcards.
    
    \item \textbf{Automaton-Based Methods:}  
    Implement finite automata to handle wildcard searches. While theoretically efficient, automaton-based implementations are more complex and harder to manage compared to tries.
\end{itemize}

These alternatives generally have higher time and space complexities or are more complex to implement, making them less suitable compared to the trie-based approach.

\section*{Similar Problems to This One}

Similar problems that involve dynamic word storage and flexible search capabilities include:

\begin{itemize}
    \item \textbf{Implement Magic Dictionary:}  
    Design a data structure that supports adding new words and searching for words that match with exactly one character difference.
    \index{Implement Magic Dictionary}
    
    \item \textbf{Word Search II:}  
    Given a grid of letters and a list of words, find all words that can be formed in the grid by sequentially adjacent cells. Implementing a trie can optimize the search process.
    \index{Word Search II}
    
    \item \textbf{Replace Words:}  
    Replace words in a sentence with the shortest root from a dictionary. Tries can efficiently find the appropriate root for each word.
    \index{Replace Words}
    
    \item \textbf{Longest Word in Dictionary:}  
    Find the longest word in a dictionary that can be built one character at a time by other words in the dictionary. A trie facilitates checking the existence of prefixes.
    \index{Longest Word in Dictionary}
\end{itemize}

These problems share the common theme of managing and searching words dynamically, often requiring efficient data structures like tries to handle large datasets and complex search patterns.

\section*{Things to Keep in Mind and Tricks}

When implementing the trie-based \texttt{WordDictionary}, consider the following tips and best practices:

\begin{itemize}
    \item \textbf{Efficient Node Representation:}  
    Use dictionaries or fixed-size arrays (for the 26 lowercase letters) to store child nodes, balancing between speed and memory usage.
    \index{Efficient Node Representation}
    
    \item \textbf{Recursive vs. Iterative Search:}  
    Implementing the search recursively simplifies handling wildcards, but be cautious of recursion depth limits with very long words.
    \index{Recursive Search}
    
    \item \textbf{Handling Wildcards Efficiently:}  
    Optimize the recursive search by pruning paths early when mismatches are detected, reducing unnecessary computations.
    \index{Handling Wildcards}
    
    \item \textbf{Memory Management:}  
    To conserve memory, consider sharing common prefixes and avoiding redundant nodes.
    \index{Memory Management}
    
    \item \textbf{Edge Case Handling:}  
    Ensure the implementation gracefully handles edge cases such as empty strings, words with all wildcards, and searches before any words are added.
    \index{Edge Case Handling}
    
    \item \textbf{Optimizing for Large Datasets:}  
    Given the constraint of up to \(10^5\) operations, ensure that both addition and search operations are optimized to prevent timeouts.
    \index{Optimizing for Large Datasets}
\end{itemize}

\section*{Corner and Special Cases to Test When Writing the Code}

When implementing and testing the \texttt{WordDictionary}, ensure to cover the following corner and special cases:

\begin{itemize}
    \item \textbf{Empty String:}  
    Test adding and searching for an empty string to verify proper handling.
    \index{Corner Cases}
    
    \item \textbf{Multiple Wildcards:}  
    Test search patterns with multiple wildcards in various positions (e.g., `".."`, `".a."`, `"a..a"`).
    \index{Corner Cases}
    
    \item \textbf{All Wildcards:}  
    Search with a pattern consisting entirely of wildcards (e.g., `"..."`) to ensure it matches any word of the corresponding length.
    \index{Corner Cases}
    
    \item \textbf{Repeated Words:}  
    Add the same word multiple times and search for it to confirm that duplicates do not affect search results.
    \index{Corner Cases}
    
    \item \textbf{No Words Added:}  
    Perform search operations before any words have been added to verify that searches return \texttt{False}.
    \index{Corner Cases}
    
    \item \textbf{Single Character Words:}  
    Add and search for single-character words, including those with wildcards.
    \index{Corner Cases}
    
    \item \textbf{Very Long Words:}  
    Add and search for words with maximum allowed length to test performance and recursion limits.
    \index{Corner Cases}
    
    \item \textbf{Non-Existent Patterns:}  
    Search for patterns that do not match any added words to ensure correct \texttt{False} responses.
    \index{Corner Cases}
    
    \item \textbf{Boundary Values:}  
    Test with words containing the first and last letters of the alphabet (`'a'` and `'z'`) to ensure all characters are handled correctly.
    \index{Corner Cases}
\end{itemize}

\section*{Implementation Considerations}

When implementing the \texttt{WordDictionary}, keep in mind the following considerations to ensure robustness and efficiency:

\begin{itemize}
    \item \textbf{Exception Handling:}  
    Implement proper exception handling to manage unexpected inputs or states, such as null inputs or invalid characters.
    \index{Exception Handling}
    
    \item \textbf{Performance Optimization:}  
    Optimize the search function to minimize recursive calls, especially when dealing with multiple wildcards, to enhance performance.
    \index{Performance Optimization}
    
    \item \textbf{Memory Efficiency:}  
    Use memory-efficient data structures for trie nodes to handle large numbers of words without excessive memory consumption.
    \index{Memory Efficiency}
    
    \item \textbf{Thread Safety:}  
    If the data structure is to be used in a multithreaded environment, ensure that add and search operations are thread-safe to prevent data races.
    \index{Thread Safety}
    
    \item \textbf{Scalability:}  
    Design the trie to handle up to \(10^5\) operations efficiently, considering both time and space constraints.
    \index{Scalability}
    
    \item \textbf{Testing and Validation:}  
    Rigorously test the implementation with various test cases, including all corner cases, to ensure correctness and reliability.
    \index{Testing and Validation}
    
    \item \textbf{Code Readability and Maintenance:}  
    Write clean, well-documented code with meaningful variable names and comments to facilitate maintenance and future enhancements.
    \index{Code Readability}
\end{itemize}

\section*{Performance Optimizations}

\begin{itemize}
    \item \textbf{Array-based Children:} For known character sets (e.g., lowercase letters only), using fixed-size arrays instead of dictionaries can improve access time:
    \begin{lstlisting}[language=Python]
class TrieNode:
    def __init__(self):
        self.children = [None] * 26  # for lowercase letters
        self.is_end_of_word = False
        
    def _char_to_index(self, char):
        return ord(char) - ord('a')
    \end{lstlisting}

    \item \textbf{Compressed Trie:} For sparse datasets, implement a compressed trie to reduce space:
    \begin{lstlisting}[language=Python]
class CompressedTrieNode:
    def __init__(self):
        self.children = {}  # {string: TrieNode}
        self.is_end_of_word = False
    \end{lstlisting}

    \item \textbf{Count Tracking:} Add word frequency counting for applications like autocomplete:
    \begin{lstlisting}[language=Python]
class TrieNode:
    def __init__(self):
        self.children = {}
        self.is_end_of_word = False
        self.frequency = 0  # track word frequency
        self.prefix_count = 0  # track prefix frequency
    \end{lstlisting}
\end{itemize}

\section*{Advanced Operations}

\begin{itemize}
    \item \textbf{Prefix Count:} Count words with a given prefix:
    \begin{lstlisting}[language=Python]
def countWordsWithPrefix(self, prefix: str) -> int:
    node = self._search_node(prefix)
    return node.prefix_count if node else 0
    \end{lstlisting}

    \item \textbf{Wildcard Search:} Support wildcard pattern matching:
    \begin{lstlisting}[language=Python]
def searchPattern(self, pattern: str) -> bool:
    def dfs(node, i):
        if i == len(pattern):
            return node.is_end_of_word
        if pattern[i] == '?':
            return any(dfs(child, i + 1) 
                      for child in node.children.values())
        if pattern[i] in node.children:
            return dfs(node.children[pattern[i]], i + 1)
        return False
    return dfs(self.root, 0)
    \end{lstlisting}

    \item \textbf{Autocomplete:} Implement prefix-based word suggestions:
    \begin{lstlisting}[language=Python]
def autocomplete(self, prefix: str, limit: int = 5) -> List[str]:
    node = self._search_node(prefix)
    if not node:
        return []
    
    results = []
    def dfs(node, curr_word):
        if node.is_end_of_word:
            results.append(curr_word)
        if len(results) >= limit:
            return
        for char, child in node.children.items():
            dfs(child, curr_word + char)
            
    dfs(node, prefix)
    return results
    \end{lstlisting}
\end{itemize}

\section*{Common Applications}

\begin{itemize}
    \item \textbf{Spell Checker:} Implement a basic spell checker with suggestions:
    \begin{itemize}
        \item Edit distance calculations
        \item Prefix-based suggestions
        \item Common misspelling patterns
    \end{itemize}

    \item \textbf{Type-Ahead Search:} Real-time search suggestions:
    \begin{itemize}
        \item Frequency-based ordering
        \item Prefix matching
        \item Fuzzy matching support
    \end{itemize}

    \item \textbf{IP Routing Tables:} Using tries for IP address lookup:
    \begin{itemize}
        \item Binary trie for IP addresses
        \item Prefix matching for subnet masks
        \item Route aggregation
    \end{itemize}

    \item \textbf{Dictionary Implementation:} Enhanced dictionary features:
    \begin{itemize}
        \item Word definition storage
        \item Part of speech tagging
        \item Etymology tracking
    \end{itemize}
\end{itemize}

\section*{Best Practices for Production Use}

\begin{itemize}
    \item \textbf{Memory Management:}
    \begin{itemize}
        \item Implement periodic cleanup of unused nodes
        \item Use weak references for large datasets
        \item Consider memory-mapped storage for huge dictionaries
    \end{itemize}

    \item \textbf{Concurrency:}
    \begin{itemize}
        \item Implement thread-safe operations
        \item Use read-write locks for better performance
        \item Consider concurrent data structures for children
    \end{itemize}

    \item \textbf{Persistence:}
    \begin{itemize}
        \item Implement serialization/deserialization
        \item Support incremental updates
        \item Handle versioning for stored tries
    \end{itemize}
\end{itemize}

\section*{Conclusion}

The trie-based implementation of the \texttt{WordDictionary} class provides an efficient and scalable solution for adding and searching words, including those with wildcard characters. By leveraging the structured nature of tries, the data structure ensures quick insertion and flexible search capabilities, making it well-suited for handling large datasets with up to \(10^5\) operations. This approach balances time and space complexities effectively, offering a robust solution compared to alternative methods like hash tables or brute-force searches.

\printindex