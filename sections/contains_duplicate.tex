\problemsection{Contains Duplicate}
\label{problem:Contains_Duplicate}

The **Contains Duplicate** problem is a fundamental challenge in array manipulation, testing oneâ€™s ability to efficiently detect duplicates in an array. While simple in its premise, this problem offers opportunities to explore trade-offs between time complexity, space complexity, and data structure selection.

\subsection*{Problem Statement}
Given an integer array \texttt{nums}, return \texttt{true} if any value appears at least twice in the array, and \texttt{false} if every element is distinct.

\textbf{Input:}
- An integer array \texttt{nums}.

\textbf{Output:}
- A boolean indicating whether duplicates exist.

\textbf{Example 1:}
\begin{verbatim}
Input: nums = [1,2,3,1]
Output: true
\end{verbatim}

\textbf{Example 2:}
\begin{verbatim}
Input: nums = [1,2,3,4]
Output: false
\end{verbatim}

\textbf{Example 3:}
\begin{verbatim}
Input: nums = [1,1,1,3,3,4,3,2,4,2]
Output: true
\end{verbatim}

\subsection*{Algorithmic Approaches}
Several methods can be used to solve this problem, each with its own trade-offs:

\begin{enumerate}
    \item \textbf{Sorting:}  
    Sort the array and check if any consecutive elements are equal. While this approach is simple and intuitive, it modifies the input array and has a time complexity of \(O(n \log n)\) due to sorting. It requires \(O(1)\) space if the sorting is done in place, but \(O(n)\) if a copy of the array is made\sidenote{Sorting is suitable when modifying the array is allowed and space efficiency is a priority}.

    \item \textbf{Hash Set:}  
    Use a hash set to store elements as you iterate through the array. If an element is already in the set, return \texttt{true}. Otherwise, add the element to the set. This approach has a time complexity of \(O(n)\) and a space complexity of \(O(n)\), making it optimal in terms of time but less space-efficient\sidenote{Hash sets are ideal for quick lookups, offering \(O(1)\) average-case complexity per operation}.

    \item \textbf{Brute Force:}  
    Check every pair of elements in the array to see if they are equal. This method has a time complexity of \(O(n^2)\) and should be avoided for large input sizes\sidenote{Brute force methods are only viable for small arrays where performance is not a concern}.
\end{enumerate}

\subsection*{Python Implementation}
The following is an implementation using a hash set for optimal time complexity:

\begin{fullwidth}
\begin{lstlisting}[language=Python]
class Solution:
    def containsDuplicate(self, nums: List[int]) -> bool:
        seen = set()
        
        for num in nums:
            if num in seen:
                return True
            seen.add(num)
        
        return False
\end{lstlisting}
\end{fullwidth}

\textbf{Explanation:}
\begin{itemize}
    \item The \texttt{seen} set is used to track elements encountered in the array\sidenote{Sets in Python provide \(O(1)\) average-time complexity for insertions and lookups}.
    \item For each element in \texttt{nums}, the algorithm checks if it is already in the set. If yes, it immediately returns \texttt{true}.
    \item If no duplicates are found after processing all elements, it returns \texttt{false}.
\end{itemize}

\subsection*{Why This Approach?}
The hash set approach is chosen for its balance of simplicity and efficiency. It avoids the \(O(n \log n)\) overhead of sorting and the \(O(n^2)\) inefficiency of brute force, making it the optimal choice for most scenarios.

\subsection*{Alternative Approaches}
\begin{itemize}
    \item **Sorting Method:**  
    Sort the array and check for consecutive duplicates. This approach avoids extra space but is slower than the hash set approach:
    \begin{lstlisting}[language=Python]
    class Solution:
        def containsDuplicate(self, nums: List[int]) -> bool:
            nums.sort()
            for i in range(len(nums) - 1):
                if nums[i] == nums[i + 1]:
                    return True
            return False
    \end{lstlisting}

    \item **Brute Force:**  
    Compare each pair of elements, which is straightforward but inefficient for large arrays:
    \begin{lstlisting}[language=Python]
    class Solution:
        def containsDuplicate(self, nums: List[int]) -> bool:
            for i in range(len(nums)):
                for j in range(i + 1, len(nums)):
                    if nums[i] == nums[j]:
                        return True
            return False
    \end{lstlisting}
\end{itemize}

\subsection*{Similar Problems to This One}
\begin{itemize}
    \item \textbf{Contains Duplicate II:} Check for duplicates within a given index distance \(k\).
    \item \textbf{Contains Duplicate III:} Check for duplicates where the absolute difference between values is within a given range.
    \item \textbf{Intersection of Two Arrays:} Find common elements between two arrays.
    \item \textbf{Unique Elements in an Array:} Identify and return the unique elements in the array.
\end{itemize}

\subsection*{Things to Keep in Mind and Tricks}
\begin{itemize}
    \item Ensure the hash set approach is used only when extra space is permissible.
    \item Sorting modifies the input array, which may not be acceptable in all scenarios. Use a copy if the original array must remain intact.
    \item For small arrays, brute force may suffice due to its simplicity.
    \item Always test edge cases like empty arrays, arrays with one element, and arrays with all identical elements.
\end{itemize}

\subsection*{Complexities}
\begin{itemize}
    \item **Hash Set Approach:**
        \begin{itemize}
            \item \textbf{Time Complexity:} \(O(n)\), for iterating through the array.
            \item \textbf{Space Complexity:} \(O(n)\), for storing elements in the hash set.
        \end{itemize}
    \item **Sorting Approach:**
        \begin{itemize}
            \item \textbf{Time Complexity:} \(O(n \log n)\), due to sorting.
            \item \textbf{Space Complexity:} \(O(1)\) (if sorting is done in place) or \(O(n)\) (if using a copy of the array).
        \end{itemize}
    \item **Brute Force:**
        \begin{itemize}
            \item \textbf{Time Complexity:} \(O(n^2)\), for comparing all pairs of elements.
            \item \textbf{Space Complexity:} \(O(1)\).
        \end{itemize}
\end{itemize}

\subsection*{Conclusion}
The **Contains Duplicate** problem is a straightforward yet essential challenge in array manipulation. The hash set approach provides the optimal balance of simplicity and efficiency, making it the preferred method in most cases. By understanding the trade-offs among the various approaches, you can tailor your solution to fit specific problem constraints and resource limitations.